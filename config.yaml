alpha: 0
batch_size: 64
beta: 0
bptt: 70
checkpoint: ''
data: ''
dataset: PTB
dropout_connect: 0.7
dropout_emb: 0.6
dropout_forward: 0.25
dropout_words: 0.1
emb_dim: 750
epochs: 1000
gamma: 0
grad_clip: 0.1
hidden_dim: 1350
layers: 3
learning_rate: 0.0012
learning_rate_thresholds: 0.0
log_interval: 1000
momentum: 0.0
num_parameters: 31699150
projection: false
prune: 0.0
pseudo_derivative_width: 3.6
rnn_type: egru
scheduler: cosine
scheduler_start: 700
scratch: ''
seed: 13541
thr_init_mean: 0.01
wandb: true
weight_decay: 0.1
weight_init_gain: 1.0
